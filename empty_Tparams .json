{
    "experiment_name": "",
    "n_epochs": 100,
    "batch_size": 8,
    "num_workers": 8,
    "learning_rate": 0.0001,
    "weight_decay": 0,
    "gradient_clipping": 0.5,
    "pca": true,
    "method": "swin_transformers",
    "input_size": [
        256,
        256
    ],
    "train_size": [
        256,
        256
    ],
    "num_class_lc": 8,
    "num_class_sau": 10,
    "num_class_esa": 10,
    "sources": [
        "dtm",
        "lc",
        "esa",
        "sau"
    ],
    "targets": [
        "ndvi"
    ],
    "root_dir": "",
    "num_patches": 256,
    "embed_dim": 128,
    "embedding_type": "sinusoidal",
    "dropout": 0.1,
    "patch_size": 16,
    "num_layers_transformers": 6,
    "num_heads": 8,
    "mlp_ratio": 4,
    "attention_dropout": 0.1,
    "drop_path_rate": 0.0,
    "activation": "gelu",
    "conf_rgb": {
        "channels": [
            3,
            16
        ],
        "kernels": [
            3
        ]
    },
    "conf_hs": {
        "channels": [
            182,
            128,
            64,
            32
        ],
        "kernels": [
            3,
            3,
            3
        ]
    },
    "conf_dem": {
        "channels": [
            1,
            8,
            16
        ],
        "kernels": [
            3,
            3
        ]
    },
    "conf_sar": {
        "channels": [
            2,
            8,
            16
        ],
        "kernels": [
            3,
            3
        ]
    },
    "conf_lc": {
        "channels": [
            8,
            16
        ],
        "kernels": [
            3
        ]
    },
    "conf_sau": {
        "channels": [
            10,
            16
        ],
        "kernels": [
            3
        ]
    },
    "conf_esa": {
        "channels": [
            10,
            16
        ],
        "kernels": [
            3
        ]
    },
    "mean_dict_01": "",
    "std_dict_01": "",
    "max_dict_01": "",
    "max_dict": "",
    "min_dict": ""
}